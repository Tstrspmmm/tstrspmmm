<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Scale Reader App</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="tesseract.js" onerror="document.getElementById('debugText').textContent='Error: Failed to load tesseract.js. Check file path or server.'"></script>
</head>
<body class="bg-gray-100 font-sans">
  <div class="container mx-auto p-4 max-w-md">
    <h1 class="text-2xl font-bold text-center mb-4">Scale Reader App</h1>
    <p class="text-center text-gray-600 mb-4">Point your iPhone camera at your kitchen scale to log weight readings.</p>

    <div class="mb-4">
      <video id="video" class="w-full rounded-lg shadow-md" autoplay playsinline></video>
      <canvas id="canvas" class="hidden"></canvas>
    </div>

    <div class="flex justify-center space-x-4 mb-4">
      <button id="startBtn" class="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600">Start Camera</button>
      <button id="captureBtn" class="bg-green-500 text-white px-4 py-2 rounded hover:bg-green-600 hidden">Manual Capture</button>
      <button id="showImageBtn" class="bg-purple-500 text-white px-4 py-2 rounded hover:bg-purple-600 hidden">Show Preprocessed Image</button>
    </div>

    <div id="preprocessedImage" class="mb-4 hidden">
      <img id="processedImg" class="w-full rounded-lg shadow-md" alt="Preprocessed Image">
    </div>

    <div id="currentReading" class="text-center text-lg font-semibold mb-4">
      Current Weight: <span id="weight">0</span> g
    </div>

    <div id="pourRate" class="text-center text-md text-gray-700 mb-4">
      Pour Rate: <span id="rate">0</span> g/s
    </div>

    <div id="debug" class="text-center text-sm text-gray-500 mb-4">
      Debug: <span id="debugText">Waiting for capture...</span>
    </div>

    <div class="bg-white p-4 rounded-lg shadow-md">
      <h2 class="text-lg font-bold mb-2">Log</h2>
      <ul id="logList" class="text-sm text-gray-600 max-h-40 overflow-y-auto"></ul>
      <button id="clearLogBtn" class="mt-2 bg-red-500 text-white px-4 py-2 rounded hover:bg-red-600 w-full">Clear Log</button>
    </div>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const captureBtn = document.getElementById('captureBtn');
    const showImageBtn = document.getElementById('showImageBtn');
    const processedImg = document.getElementById('processedImg');
    const preprocessedImage = document.getElementById('preprocessedImage');
    const weightDisplay = document.getElementById('weight');
    const rateDisplay = document.getElementById('rate');
    const debugText = document.getElementById('debugText');
    const logList = document.getElementById('logList');
    const clearLogBtn = document.getElementById('clearLogBtn');

    let stream = null;
    let lastWeight = 0;
    let lastTime = Date.now();
    let readings = JSON.parse(localStorage.getItem('scaleReadings')) || [];
    let autoCaptureInterval = null;
    let worker = null;

    // Log Tesseract availability
    console.log('Tesseract loaded:', !!window.Tesseract);
    if (window.Tesseract) {
      debugText.textContent = 'Tesseract.js loaded successfully';
    } else {
      debugText.textContent = 'Error: Tesseract.js not loaded';
    }

    // Load saved readings
    function loadReadings() {
      logList.innerHTML = '';
      readings.forEach(reading => {
        const li = document.createElement('li');
        li.textContent = `${reading.time}: ${reading.weight} g (Rate: ${reading.rate} g/s)`;
        logList.appendChild(li);
      });
    }
    loadReadings();

    // Start camera and initialize worker
    async function startCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment' }
        });
        video.srcObject = stream;
        startBtn.classList.add('hidden');
        captureBtn.classList.remove('hidden');
        showImageBtn.classList.remove('hidden');

        // Initialize Tesseract worker
        worker = await Tesseract.createWorker('eng', 1, {
          workerPath: 'worker.js',
          // Optional: Local language data (uncomment if hosting locally)
          // langPath: './',
          corePath: 'https://cdn.jsdelivr.net/npm/tesseract.js-core@v5.0.0',
          logger: m => console.log(m)
        });
        await worker.setParameters({
          tessedit_char_whitelist: '0123456789.g',
          tessedit_pageseg_mode: Tesseract.PSM.SINGLE_BLOCK
        });

        // Start auto-capture every 3 seconds
        autoCaptureInterval = setInterval(captureImage, 3000);
      } catch (err) {
        debugText.textContent = 'Error: ' + err.message;
      }
    }

    // Capture and process image
    async function captureImage() {
      try {
        if (!worker) {
          debugText.textContent = 'Error: Tesseract worker not initialized';
          console.error('Tesseract worker not initialized');
          return;
        }

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Preprocess: Convert to grayscale, enhance contrast, and apply thresholding
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const data = imageData.data;
        // Simple histogram equalization for contrast
        const histogram = new Array(256).fill(0);
        for (let i = 0; i < data.length; i += 4) {
          const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
          histogram[Math.floor(avg)]++;
        }
        const totalPixels = canvas.width * canvas.height;
        let cumsum = 0;
        const cdf = histogram.map(count => cumsum += count / totalPixels);
        for (let i = 0; i < data.length; i += 4) {
          const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
          const equalized = Math.floor(cdf[Math.floor(avg)] * 255);
          data[i] = data[i + 1] = data[i + 2] = equalized;
        }

        // Thresholding for 7-segment displays
        for (let i = 0; i < data.length; i += 4) {
          const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
          const threshold = avg > 50 ? 255 : 0; // Lowered for faint LCD
          data[i] = data[i + 1] = data[i + 2] = threshold;
        }

        // Stronger dilation to connect 7-segment gaps
        const tempData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        for (let y = 2; y < canvas.height - 2; y++) {
          for (let x = 2; x < canvas.width - 2; x++) {
            const i = (y * canvas.width + x) * 4;
            if (data[i] === 255) {
              // 5x5 kernel for stronger dilation
              for (let dy = -2; dy <= 2; dy++) {
                for (let dx = -2; dx <= 2; dx++) {
                  const ni = ((y + dy) * canvas.width + (x + dx)) * 4;
                  tempData.data[ni] = tempData.data[ni + 1] = tempData.data[ni + 2] = 255;
                }
              }
            }
          }
        }
        ctx.putImageData(tempData, 0, 0);

        // Update preprocessed image for debugging
        processedImg.src = canvas.toDataURL('image/png');

        debugText.textContent = 'Processing image...';
        const { data: { text } } = await worker.recognize(canvas);
        debugText.textContent = `OCR Output: "${text}"`;

        const weightMatch = text.match(/\d+(\.\d+)?/);
        if (weightMatch) {
          const weight = parseFloat(weightMatch[0]);
          const currentTime = Date.now();
          const timeDiff = (currentTime - lastTime) / 1000;
          const weightDiff = weight - lastWeight;
          const pourRate = timeDiff > 0 ? (weightDiff / timeDiff).toFixed(2) : 0;

          weightDisplay.textContent = weight;
          rateDisplay.textContent = pourRate;

          const reading = {
            time: new Date().toLocaleTimeString(),
            weight: weight,
            rate: pourRate
          };
          readings.push(reading);
          localStorage.setItem('scaleReadings', JSON.stringify(readings));
          loadReadings();

          lastWeight = weight;
          lastTime = currentTime;
        } else {
          debugText.textContent = `No valid number found in "${text}"`;
        }
      } catch (err) {
        debugText.textContent = 'Error: ' + err.message;
        console.error('Capture error:', err);
      }
    }

    // Show preprocessed image
    showImageBtn.addEventListener('click', () => {
      preprocessedImage.classList.toggle('hidden');
    });

    // Clear log
    function clearLog() {
      readings = [];
      localStorage.setItem('scaleReadings', JSON.stringify(readings));
      loadReadings();
    }

    // Event listeners
    startBtn.addEventListener('click', startCamera);
    captureBtn.addEventListener('click', captureImage);
    clearLogBtn.addEventListener('click', clearLog);

    // Stop stream, auto-capture, and worker when page unloads
    window.addEventListener('beforeunload', () => {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (autoCaptureInterval) {
        clearInterval(autoCaptureInterval);
      }
      if (worker) {
        worker.terminate();
      }
    });
  </script>
</body>
</html>
